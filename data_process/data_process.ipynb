{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "specific-acoustic",
   "metadata": {},
   "source": [
    "# This file is to process data before training:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-animal",
   "metadata": {},
   "source": [
    "## 1. k-mer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "transparent-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def get_basic_group(n, k, letters, m='', k_letter=''):\n",
    "    if m == '':\n",
    "        m = n - k\n",
    "        k_letter = list(letters[:n])\n",
    "    if n == m + 1: return k_letter\n",
    "    num_of_perm = []\n",
    "    for perm in get_basic_g(n - 1, k, letters, m, k_letter):\n",
    "        temp_letter = [i for i in k_letter]\n",
    "        num_of_perm += [perm + i for i in temp_letter]\n",
    "    return num_of_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exterior-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmer_features():\n",
    "    k = 0\n",
    "    while 1 > k or k > 8:\n",
    "        k = int(input('input k(>=1)：'))\n",
    "\n",
    "    basic = ['A', 'C', 'G', 'T']\n",
    "    xulie = []\n",
    "\n",
    "    with open('xulie_600.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i in enumerate(reader):\n",
    "            xulie.append(i[1][1])\n",
    "\n",
    "    basic_group = get_basic_group(len(basic), k, basic)\n",
    "    base_group_count = list(dict(zip(basic_group, [0 for _ in range(len(basic_group))])) for _ in range(len(xulie)))\n",
    "\n",
    "    for i in range(len(xulie)):\n",
    "        for j in range(len(xulie[i])-k+1):\n",
    "            base_group_count[i][xulie[i][j:j+k]] += 1\n",
    "\n",
    "    # normalization\n",
    "    feat_f = [list(base_group_count[i].values()) for i in range(len(base_group_count))]\n",
    "    feat = []\n",
    "    for i in range(len(feat_f)):\n",
    "        sum_f = 0\n",
    "        for j in range(len(basic_group)):\n",
    "            sum_f += feat_f[i][j]\n",
    "        feat.append([round(feat_f[i][n] / sum_f, 4) for n in range(len(feat_f[0]))])\n",
    "    print('feat.len():', len(feat))\n",
    "\n",
    "    with open('1. k-mer/feat_' + str(k) + '.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in range(len(feat)):\n",
    "            writer.writerow(feat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "light-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input k(>=1)：1\n",
      "feat.len(): 600\n"
     ]
    }
   ],
   "source": [
    "get_kmer_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-synthetic",
   "metadata": {},
   "source": [
    "## 2. SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "descending-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def mySMOTE():\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    with open('1. k-mer/feat_1.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for value in reader:\n",
    "            X.append(np.array(value))\n",
    "    with open('xulie_600.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for value in reader:\n",
    "            y.append(int(value[0]))\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    sm = SMOTE(random_state=666)\n",
    "    X_res, y_res = sm.fit_resample(X, y)\n",
    "    X_res = X_res.tolist()\n",
    "    X_res = [[round(i, 4) for i in j] for j in X_res]\n",
    "    X_res = np.array(X_res)\n",
    "    print(X_res.shape, y_res.shape)\n",
    "    print(X_res[len(X_res) - 1], y_res[len(y_res) - 1])\n",
    "\n",
    "    with open('2. SMOTE/feat_smote.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in X_res:\n",
    "            writer.writerow(i)\n",
    "\n",
    "    with open('2. SMOTE/label_smote.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for i in range(len(y_res)):\n",
    "            writer.writerow([i, y_res[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "british-station",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 4) (600,)\n",
      "(1460, 4) (1460,)\n",
      "[0.2983 0.2131 0.245  0.2437] 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "mySMOTE()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-disability",
   "metadata": {},
   "source": [
    "## 3. Constructing graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "shared-dress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_similarity(x, y):\n",
    "    num = x.dot(y.T)\n",
    "    v_module = np.linalg.norm(x) * np.linalg.norm(y)\n",
    "    return num / v_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "given-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the adjacency matrix\n",
    "def create_adj():\n",
    "    w = 0.0\n",
    "    while w <= 0.0:\n",
    "        w = float(input('input threshold w(0~1):'))\n",
    "\n",
    "    data = []\n",
    "    with open('2. SMOTE/feat_smote.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for i in reader:\n",
    "            data.append(np.array([float(j) for j in i]))\n",
    "    data = np.array(data)\n",
    "\n",
    "    adj = np.zeros((len(data), len(data)))\n",
    "    similarity = np.zeros((len(data), len(data)))\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range(i + 1, len(data)):\n",
    "            similarity[i][j] = similarity[j][i] = cos_similarity(data[i], data[j])\n",
    "            if similarity[i][j] > w:\n",
    "                adj[i][j] = 1\n",
    "                adj[j][i] = 1\n",
    "\n",
    "    f_1 = open('3. Constructing graph/similar_cos' + str(w) + '.csv', 'w', encoding='utf-8', newline='')\n",
    "    writer_1 = csv.writer(f_1)\n",
    "    f_2 = open('3. Constructing graph/adj_cos' + str(w) + '.csv', 'w', encoding='utf-8', newline='')\n",
    "    writer_2 = csv.writer(f_2)\n",
    "\n",
    "    edge_count = []\n",
    "    iso_node = 0\n",
    "    for i in range(len(data)):\n",
    "        e_sum = 0\n",
    "        writer_1.writerow(similarity[i])\n",
    "        writer_2.writerow(adj[i])\n",
    "        for j in range(len(data)):\n",
    "            e_sum += adj[i][j]\n",
    "        if e_sum == 0:\n",
    "            iso_node += 1\n",
    "        edge_count.append(e_sum)\n",
    "\n",
    "    f_1.close()\n",
    "    f_2.close()\n",
    "    \n",
    "    print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "coral-article",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input threshold w(0~1):0.9995\n",
      "finish!\n"
     ]
    }
   ],
   "source": [
    "create_adj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "\n",
    "def create_graph_dgl():\n",
    "    nodes = 1460\n",
    "    G = dgl.DGLGraph()\n",
    "    G.add_nodes(nodes)\n",
    "    edges_u = []\n",
    "    edges_v = []\n",
    "\n",
    "    csv_reader = csv.reader(open(\"3. Constructing graph/adj_cos0.9995.csv\"))\n",
    "    for row, u in enumerate(csv_reader):\n",
    "        for column, v in enumerate(u):\n",
    "            if int(float(v)):\n",
    "                edges_u.append(row)\n",
    "                edges_v.append(column)\n",
    "    G.add_edges(edges_u, edges_v)\n",
    "\n",
    "    with open('../data/graph_dgl.pkl', 'wb') as f:\n",
    "        pickle.dump([G], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_graph_dgl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_npy():\n",
    "    feat1 = []\n",
    "    csv_reader = csv.reader(open(\"2. SMOTE/feat_smote.csv\"))\n",
    "    for row in csv_reader:\n",
    "        feat_row = []\n",
    "        for column in row:\n",
    "            feat_row.append(float(column))\n",
    "        feat1.append(feat_row)\n",
    "    feat1 = np.array(feat1, dtype=np.float32)\n",
    "    \n",
    "    np.save('../data/features.npy', np.array([feat1], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_features_npy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "burning-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_pkl():\n",
    "    label = {}\n",
    "    csv_reader = csv.reader(open(\"2. SMOTE/label_smote.csv\"))\n",
    "    for row in csv_reader:\n",
    "        label['0_'+str(row[0])] = np.float32(row[1])\n",
    "    \n",
    "    with open('../data/label.pkl', 'wb') as f:\n",
    "        pickle.dump(label, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_label_pkl()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
